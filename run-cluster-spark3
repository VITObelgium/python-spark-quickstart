#!/bin/sh
export SPARK_HOME=/opt/spark3_2_0/
pyspark_python="./env/bin/python"
${SPARK_HOME}/bin/spark-submit --master yarn --deploy-mode cluster \
--conf spark.yarn.executorEnv.PYSPARK_PYTHON=$pyspark_python \
--conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=$pyspark_python \
--archives hdfs://hacluster/spark3_sample/spark3_example.tar.gz#env \
spark-pi.py
